<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<link rel="stylesheet" href="style.css" type="text/css">
<meta content="text/html; charset=utf-8" http-equiv="Content-Type">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="Start" href="index.html">
<link rel="Up" href="index.html">
<link title="Index of types" rel=Appendix href="index_types.html">
<link title="Index of values" rel=Appendix href="index_values.html">
<link title="Index of modules" rel=Appendix href="index_modules.html">
<link title="Index of module types" rel=Appendix href="index_module_types.html">
<link title="Obandit" rel="Chapter" href="Obandit.html"><link title="Examples" rel="Section" href="#ex">
<link title="References" rel="Section" href="#refs">
<link title="The UCB family of algorithms." rel="Subsection" href="#mdf">
<link title="The Epsilon-Greedy family of algorithms." rel="Subsection" href="#mdf">
<link title="The Exp3 family of algorithms." rel="Subsection" href="#mdf">
<link title="More Functors: The doubling trick." rel="Subsection" href="#mdf">
<title>Obandit</title>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax:{inlineMath: [ ['$','$'], ['\\(','\\)'] ],displayMath: [ ['$$','$$'], ['\\[','\\]'] ]},TeX:{Macros: {C: '{\\mathbb C}',R: '{\\mathbb R}',Q: '{\\mathbb Q}',Z: '{\\mathbb Z}',bm: ['{\\boldsymbol #1}', 1],argmax: '\\mathop{\\rm arg\\,max}\\limits',argmin: '\\mathop{\\rm arg\\,min}\\limits'}}});
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
<div class="navbar">&nbsp;<a class="up" href="index.html" title="Index">Up</a>
&nbsp;</div>
<h1>Module <a href="type_Obandit.html">Obandit</a></h1>

<pre><span class="keyword">module</span> Obandit: <code class="code"><span class="keyword">sig</span></code> <a href="Obandit.html">..</a> <code class="code"><span class="keyword">end</span></code></pre><div class="info module top">
Ocaml Multi-Armed Bandits
<p>

Obandit is an OCaml module for multi-armed bandits. It supports the
EXP, UCB and Epsilon-greedy family of algorithms.
<p>

  <em>Version 0.2 — <a href="http://freux.fr/oss/obandit.html ">homepage</a></em> 
  <img src="http://freux.fr/kroliki.jpg" alt="rabbits" width="600">  
<p>

  <h1 id="mutband">Bandit Modules</h1>
<p>

  This library implements multi-armed bandits as modules.
  A bandit module is obtained by calling a functor with a bandit module
  parameter. The parameter usually gives the number $K$ of arms and
  the hyperparameters of the bandit.<br>
</div>
<hr width="100%">

<pre><span class="keyword">module type</span> <a href="Obandit.Bandit.html">Bandit</a> = <code class="code"><span class="keyword">sig</span></code> <a href="Obandit.Bandit.html">..</a> <code class="code"><span class="keyword">end</span></code></pre><div class="info">
A bandit algorithm.
</div>
<br>
$$
  $$
<p>

  Bandit modules are instanciated using functors. Depending on the
  algorithm type used, the module parameter varies.
<p>

  For instance, the UCB1 bandit module for 3 arms is obtained with:
<p>

  <code class="code"><span class="keyword">module</span>&nbsp;<span class="constructor">UCB1</span>&nbsp;=<br>
&nbsp;&nbsp;<span class="keyword">let</span>&nbsp;<span class="keyword">module</span>&nbsp;<span class="constructor">P</span>&nbsp;=&nbsp;<span class="keyword">struct</span><br>
&nbsp;&nbsp;<span class="keyword">let</span>&nbsp;k=3<br>
&nbsp;&nbsp;<span class="keyword">end</span><br>
&nbsp;&nbsp;<span class="keyword">in</span>&nbsp;<span class="constructor">MakeUCB1</span>(<span class="constructor">P</span>)</code>
<p>

  The following algorithms are available:<br>
<br>
<h2 id="mdf">The UCB family of algorithms.</h2>
<p>

  We use the viewpoint of the survey <code class="code">[1]</code>.
<p>

  <h3 id="apu">MakeAlphaPhiUCB: $(\alpha,\psi)$-UCB </h3>
<p>

  At time $t$, the $(\alpha,\psi)$-UCB algorithm<code class="code">[1]</code> is taking action:
<p>

  $$
  \argmax_{i=1,\cdots,K} \quad \left[
  \widehat{\mu_i}+(\psi^{*})^{-1}\left(\frac{\alpha\ln t}{T_i} \right) 
  \right]
  $$ 
<p>

  where $\alpha &gt; 0$ is a hyperparameter, $\widehat{\mu_i}$ is the estimate of
  the average reward of arm $i$, $T_i$ is the number of times arm $ i$ was
  visited so far and $\psi^*$ denotes the Legendre-Fenchel transform of a
  convex function $\psi$.
<p>

  The pseudo-regret $\bar{R_n}$ has the following bound at round $n$:
  $$ 
  \bar{R_n} \leq \sum_{i:\Delta_i &gt; 0} \left( \frac{\alpha \Delta_i}{\psi^* (\Delta_i / 2 )} \ln n + \frac{\alpha }{\alpha-2 } \right)
  $$ 
<p>

  where $ \Delta_i = \mu^* - \mu_i $ is the suboptimality parameter of arm $ i$.<br>

<pre><code><span id="TYPEbanditEstimates"><span class="keyword">type</span> <code class="type"></code>banditEstimates</span> = {</code></pre><table class="typetable">
<tr>
<td align="left" valign="top" >
<code>&nbsp;&nbsp;</code></td>
<td align="left" valign="top" >
<code><span id="TYPEELTbanditEstimates.t">t</span>&nbsp;: <code class="type">int</code>;</code></td>
<td class="typefieldcomment" align="left" valign="top" ><code>(*</code></td><td class="typefieldcomment" align="left" valign="top" ><div class="info ">
The index of the step<br>
</div>
</td><td class="typefieldcomment" align="left" valign="bottom" ><code>*)</code></td>
</tr>
<tr>
<td align="left" valign="top" >
<code>&nbsp;&nbsp;</code></td>
<td align="left" valign="top" >
<code><span id="TYPEELTbanditEstimates.a">a</span>&nbsp;: <code class="type">int</code>;</code></td>
<td class="typefieldcomment" align="left" valign="top" ><code>(*</code></td><td class="typefieldcomment" align="left" valign="top" ><div class="info ">
The last action taken.<br>
</div>
</td><td class="typefieldcomment" align="left" valign="bottom" ><code>*)</code></td>
</tr>
<tr>
<td align="left" valign="top" >
<code>&nbsp;&nbsp;</code></td>
<td align="left" valign="top" >
<code><span id="TYPEELTbanditEstimates.nVisits">nVisits</span>&nbsp;: <code class="type">int list</code>;</code></td>
<td class="typefieldcomment" align="left" valign="top" ><code>(*</code></td><td class="typefieldcomment" align="left" valign="top" ><div class="info ">
The visit counts by arm.<br>
</div>
</td><td class="typefieldcomment" align="left" valign="bottom" ><code>*)</code></td>
</tr>
<tr>
<td align="left" valign="top" >
<code>&nbsp;&nbsp;</code></td>
<td align="left" valign="top" >
<code><span id="TYPEELTbanditEstimates.u">u</span>&nbsp;: <code class="type">float list</code>;</code></td>
<td class="typefieldcomment" align="left" valign="top" ><code>(*</code></td><td class="typefieldcomment" align="left" valign="top" ><div class="info ">
The cumulative arm reward observations.<br>
</div>
</td><td class="typefieldcomment" align="left" valign="bottom" ><code>*)</code></td>
</tr></table>
}

<div class="info ">
The inner state of a bandit that maintains estimates of arm means.<br>
</div>


<pre><span class="keyword">module type</span> <a href="Obandit.AlphaPhiUCBParam.html">AlphaPhiUCBParam</a> = <code class="code"><span class="keyword">sig</span></code> <a href="Obandit.AlphaPhiUCBParam.html">..</a> <code class="code"><span class="keyword">end</span></code></pre><div class="info">
Use to instanciate a <code class="code"><span class="constructor">Bandit</span></code> from <code class="code"><span class="constructor">MakeAlphaPhiUCB</span></code> by giving $\alpha$ and $\phi$.
</div>

<pre><span class="keyword">module</span> <a href="Obandit.MakeAlphaPhiUCB.html">MakeAlphaPhiUCB</a>: <div class="sig_block"><code class="code"><span class="keyword">functor</span>&nbsp;(</code><code class="code"><span class="constructor">P</span></code><code class="code">&nbsp;:&nbsp;</code><code class="type"><a href="Obandit.AlphaPhiUCBParam.html">AlphaPhiUCBParam</a></code><code class="code">)&nbsp;<span class="keywordsign">-&gt;</span>&nbsp;</code><code class="type"><a href="Obandit.Bandit.html">Bandit</a></code><code class="type">  with type bandit = banditEstimates</code></div></pre><div class="info">
The $(\alpha,\psi)$-UCB Bandit for stochastic regret minimization described in <code class="code">[1]</code>.
</div>
<br>
<h3 id="apu">MakeAlphaUCB: $\alpha$-UCB </h3>
<p>

  The $\alpha$-UCB algorithm<code class="code">[5]</code> uses $ \psi(\lambda) = \lambda^2 / 8 $.
  It chooses the action:
<p>

  $$ 
  \argmax_{i=1,\cdots,K} \left[ \widehat{\mu_i} +  \sqrt{ \frac{\alpha \ln t}{2 T_i} } \right]
  $$ 
<p>

  This gives a pseudo-regret bound of:
<p>

  $$ 
  \bar{ R_n} \leq  \sum_{i:\Delta_i &gt; 0} \left( \frac{2 \alpha} { \Delta_i } \ln n + \frac{\alpha}{\alpha - 2} \right)
  $$<br>

<pre><span class="keyword">module type</span> <a href="Obandit.AlphaUCBParam.html">AlphaUCBParam</a> = <code class="code"><span class="keyword">sig</span></code> <a href="Obandit.AlphaUCBParam.html">..</a> <code class="code"><span class="keyword">end</span></code></pre><div class="info">
Use to instanciate a <code class="code"><span class="constructor">Bandit</span></code> from <code class="code"><span class="constructor">MakeAlphaUCB</span></code> by giving $\alpha$.
</div>

<pre><span class="keyword">module</span> <a href="Obandit.MakeAlphaUCB.html">MakeAlphaUCB</a>: <div class="sig_block"><code class="code"><span class="keyword">functor</span>&nbsp;(</code><code class="code"><span class="constructor">P</span></code><code class="code">&nbsp;:&nbsp;</code><code class="type"><a href="Obandit.AlphaUCBParam.html">AlphaUCBParam</a></code><code class="code">)&nbsp;<span class="keywordsign">-&gt;</span>&nbsp;</code><code class="type"><a href="Obandit.Bandit.html">Bandit</a></code><code class="type">  with type bandit = banditEstimates</code></div></pre><div class="info">
The $\alpha$-UCB Bandit for stochastic regret minimization described in <code class="code">[1]</code> .
</div>
<br>
<h3 id="apu">MakeUCB1: UCB1</h3>
<p>

  The UCB1 algorithm<code class="code">[5]</code> uses $\alpha = 4$.
  It chooses the action:
<p>

  $$
  \argmax_{i=1,\cdots,K} \left[ \widehat{\mu_i} +  \sqrt{ \frac{2 \ln t}{T_i} } \right]
  $$
<p>

  At round  $ n$, this gives a pseudo-regret bound of:
<p>

  $$
  \bar{R_n} \leq \sum_{i:\Delta_i &gt; 0} \left( \frac{8}{\Delta_i} \ln n + 2 \right)
  $$<br>

<pre><span class="keyword">module type</span> <a href="Obandit.KBanditParam.html">KBanditParam</a> = <code class="code"><span class="keyword">sig</span></code> <a href="Obandit.KBanditParam.html">..</a> <code class="code"><span class="keyword">end</span></code></pre><div class="info">
Use to instanciate a <code class="code"><span class="constructor">Bandit</span></code> from <code class="code"><span class="constructor">MakeUCB1</span></code>.
</div>

<pre><span class="keyword">module</span> <a href="Obandit.MakeUCB1.html">MakeUCB1</a>: <div class="sig_block"><code class="code"><span class="keyword">functor</span>&nbsp;(</code><code class="code"><span class="constructor">P</span></code><code class="code">&nbsp;:&nbsp;</code><code class="type"><a href="Obandit.KBanditParam.html">KBanditParam</a></code><code class="code">)&nbsp;<span class="keywordsign">-&gt;</span>&nbsp;</code><code class="type"><a href="Obandit.Bandit.html">Bandit</a></code><code class="type">  with type bandit = banditEstimates</code></div></pre><div class="info">
The UCB1 Bandit for stochastic regret minimization .
</div>
<br>
<h2 id="mdf">The Epsilon-Greedy family of algorithms.</h2>
<p>

  <h3 id="mdf">MakeParametrizableEpsilonGreedy: $\epsilon$-Greedy with a parametrizable rate.</h3>
<p>

  At round $t$, the $ \epsilon_t$-Greedy algorithm<code class="code">[5]</code> takes action $\argmax_{i=1,\cdots,K} \widehat{\mu_i} $
  with probability $ 1-\epsilon_t$ and an uniformly random action with probability $ \epsilon_t$.<br>

<pre><span class="keyword">module type</span> <a href="Obandit.RateBanditParam.html">RateBanditParam</a> = <code class="code"><span class="keyword">sig</span></code> <a href="Obandit.RateBanditParam.html">..</a> <code class="code"><span class="keyword">end</span></code></pre><div class="info">
Use to instanciate algorithms that need a parametrizable rate.
</div>

<pre><span class="keyword">module</span> <a href="Obandit.MakeParametrizableEpsilonGreedy.html">MakeParametrizableEpsilonGreedy</a>: <div class="sig_block"><code class="code"><span class="keyword">functor</span>&nbsp;(</code><code class="code"><span class="constructor">P</span></code><code class="code">&nbsp;:&nbsp;</code><code class="type"><a href="Obandit.RateBanditParam.html">RateBanditParam</a></code><code class="code">)&nbsp;<span class="keywordsign">-&gt;</span>&nbsp;</code><code class="type"><a href="Obandit.Bandit.html">Bandit</a></code><code class="type">  with type bandit = banditEstimates</code></div></pre><div class="info">
The $\epsilon$-Greedy Bandit with a parametrizable exploration rate.
</div>
<br>
<h3 id="mdf">MakeDecayingEpsilonGreedy: $ \epsilon_n$-Greedy with the decaying rate from <code class="code">[5]</code>.</h3>
<p>

  This uses the exploration rate decay:
  $$
  \epsilon_t = \min  \left\{ 1, \frac{cK}{d^2 t} \right\}
  $$
  where $ d &gt; 0 $ should be taken as a tight lower bound on $ \max_{i=1,\cdots,K} \Delta_i$ and $ c &gt; 0$ is a hyperparameter.<br>

<pre><span class="keyword">module type</span> <a href="Obandit.DecayingEpsilonGreedyParam.html">DecayingEpsilonGreedyParam</a> = <code class="code"><span class="keyword">sig</span></code> <a href="Obandit.DecayingEpsilonGreedyParam.html">..</a> <code class="code"><span class="keyword">end</span></code></pre><div class="info">
Use to instanciate a <code class="code"><span class="constructor">Bandit</span></code> from <code class="code"><span class="constructor">MakeDecayingEpsilonGreedy</span></code> .
</div>

<pre><span class="keyword">module</span> <a href="Obandit.MakeDecayingEpsilonGreedy.html">MakeDecayingEpsilonGreedy</a>: <div class="sig_block"><code class="code"><span class="keyword">functor</span>&nbsp;(</code><code class="code"><span class="constructor">P</span></code><code class="code">&nbsp;:&nbsp;</code><code class="type"><a href="Obandit.DecayingEpsilonGreedyParam.html">DecayingEpsilonGreedyParam</a></code><code class="code">)&nbsp;<span class="keywordsign">-&gt;</span>&nbsp;</code><code class="type"><a href="Obandit.Bandit.html">Bandit</a></code><code class="type">  with type bandit = banditEstimates</code></div></pre><div class="info">
The Epsilon-Greedy Bandit with the decaying exploration rate from <code class="code">[5]</code>.
</div>
<br>
<h3 id="mdf">MakeEpsilonGreedy: $ \epsilon_n$-Greedy with a fixed exploration rate.</h3>
<p>

  This uses a fixed exploration rate $ \epsilon$.<br>

<pre><span class="keyword">module type</span> <a href="Obandit.EpsilonGreedyParam.html">EpsilonGreedyParam</a> = <code class="code"><span class="keyword">sig</span></code> <a href="Obandit.EpsilonGreedyParam.html">..</a> <code class="code"><span class="keyword">end</span></code></pre><div class="info">
Use to instanciate a <code class="code"><span class="constructor">Bandit</span></code> from <code class="code"><span class="constructor">MakeEpsilonGreedy</span></code> .
</div>

<pre><span class="keyword">module</span> <a href="Obandit.MakeEpsilonGreedy.html">MakeEpsilonGreedy</a>: <div class="sig_block"><code class="code"><span class="keyword">functor</span>&nbsp;(</code><code class="code"><span class="constructor">P</span></code><code class="code">&nbsp;:&nbsp;</code><code class="type"><a href="Obandit.EpsilonGreedyParam.html">EpsilonGreedyParam</a></code><code class="code">)&nbsp;<span class="keywordsign">-&gt;</span>&nbsp;</code><code class="type"><a href="Obandit.Bandit.html">Bandit</a></code><code class="type">  with type bandit = banditEstimates</code></div></pre><div class="info">
The Epsilon-Greedy Bandit with a fixed exploration rate.
</div>
<br>
<h2 id="mdf">The Exp3 family of algorithms.</h2>
<p>

  <h3 id="mdf">MakeExp3: EXP3 with a parametrizable rate.</h3>
<p>

  At round $ t$, the EXP3 algorithm<code class="code">[1]</code> draws an arm from a probability
  distribution $ p$ and updates this distribution with a softmax operator:
<p>

  $
  p_{i,t+1} = \frac{\exp ( - \eta_t \widetilde{L_{i,t}})}{\sum{k=1}^{K}\text{exp}(-\eta_t \widetilde{L_{k,t}})}
  $
<p>

  where $\widetilde{L_{i,t}}$ is the cumulative probability-normalized loss at
  time $ t$ of arm $i$, $\eta_t$ is the rate at time $t$.<br>

<pre><code><span id="TYPEbanditPolicy"><span class="keyword">type</span> <code class="type"></code>banditPolicy</span> = {</code></pre><table class="typetable">
<tr>
<td align="left" valign="top" >
<code>&nbsp;&nbsp;</code></td>
<td align="left" valign="top" >
<code><span id="TYPEELTbanditPolicy.t">t</span>&nbsp;: <code class="type">int</code>;</code></td>
<td class="typefieldcomment" align="left" valign="top" ><code>(*</code></td><td class="typefieldcomment" align="left" valign="top" ><div class="info ">
The index of the step $t$.<br>
</div>
</td><td class="typefieldcomment" align="left" valign="bottom" ><code>*)</code></td>
</tr>
<tr>
<td align="left" valign="top" >
<code>&nbsp;&nbsp;</code></td>
<td align="left" valign="top" >
<code><span id="TYPEELTbanditPolicy.a">a</span>&nbsp;: <code class="type">int</code>;</code></td>
<td class="typefieldcomment" align="left" valign="top" ><code>(*</code></td><td class="typefieldcomment" align="left" valign="top" ><div class="info ">
The last action taken.<br>
</div>
</td><td class="typefieldcomment" align="left" valign="bottom" ><code>*)</code></td>
</tr>
<tr>
<td align="left" valign="top" >
<code>&nbsp;&nbsp;</code></td>
<td align="left" valign="top" >
<code><span id="TYPEELTbanditPolicy.w">w</span>&nbsp;: <code class="type">float list</code>;</code></td>
<td class="typefieldcomment" align="left" valign="top" ><code>(*</code></td><td class="typefieldcomment" align="left" valign="top" ><div class="info ">
The weights of the arm that define the policy.<br>
</div>
</td><td class="typefieldcomment" align="left" valign="bottom" ><code>*)</code></td>
</tr></table>
}

<div class="info ">
The internal state of an Exp3 bandit<br>
</div>


<pre><span class="keyword">module</span> <a href="Obandit.MakeExp3.html">MakeExp3</a>: <div class="sig_block"><code class="code"><span class="keyword">functor</span>&nbsp;(</code><code class="code"><span class="constructor">P</span></code><code class="code">&nbsp;:&nbsp;</code><code class="type"><a href="Obandit.RateBanditParam.html">RateBanditParam</a></code><code class="code">)&nbsp;<span class="keywordsign">-&gt;</span>&nbsp;</code><code class="type"><a href="Obandit.Bandit.html">Bandit</a></code><code class="type">  with type bandit = banditPolicy</code></div></pre><div class="info">
The Exp3 Bandit for adversarial regret minimization with a parametrizable learning rate.
</div>
<br>
<h3 id="mdf">MakeDecayingExp3: EXP3 with the decaying rate from <code class="code">[1]</code>.</h3>
<p>

  This variant uses the learning rate decay:
<p>

  $$
  \eta_t = \sqrt{\frac{ln K}{tK}}
  $$
<p>

  and enjoys the pseudo-regret bound:
  $$
  \bar{R_n} \leq 2 \sqrt{nK \ln K}
  $$<br>

<pre><span class="keyword">module</span> <a href="Obandit.MakeDecayingExp3.html">MakeDecayingExp3</a>: <div class="sig_block"><code class="code"><span class="keyword">functor</span>&nbsp;(</code><code class="code"><span class="constructor">P</span></code><code class="code">&nbsp;:&nbsp;</code><code class="type"><a href="Obandit.KBanditParam.html">KBanditParam</a></code><code class="code">)&nbsp;<span class="keywordsign">-&gt;</span>&nbsp;</code><code class="type"><a href="Obandit.Bandit.html">Bandit</a></code><code class="type">  with type bandit = banditPolicy</code></div></pre><div class="info">
The Exp3 Bandit for adversarial regret minimization with a decaying learning rate as per <code class="code">[1]</code>.
</div>
<br>
<h3 id="mdf">MakeFixedExp3: EXP3 with a fixed rate.</h3>
<p>

  This uses a fixed rate $\eta$.<br>

<pre><span class="keyword">module type</span> <a href="Obandit.FixedExp3Param.html">FixedExp3Param</a> = <code class="code"><span class="keyword">sig</span></code> <a href="Obandit.FixedExp3Param.html">..</a> <code class="code"><span class="keyword">end</span></code></pre><div class="info">
Use to instanciate a <code class="code"><span class="constructor">Bandit</span></code> from <code class="code"><span class="constructor">MakeFixedExp3</span></code> .
</div>

<pre><span class="keyword">module</span> <a href="Obandit.MakeFixedExp3.html">MakeFixedExp3</a>: <div class="sig_block"><code class="code"><span class="keyword">functor</span>&nbsp;(</code><code class="code"><span class="constructor">P</span></code><code class="code">&nbsp;:&nbsp;</code><code class="type"><a href="Obandit.FixedExp3Param.html">FixedExp3Param</a></code><code class="code">)&nbsp;<span class="keywordsign">-&gt;</span>&nbsp;</code><code class="type"><a href="Obandit.Bandit.html">Bandit</a></code><code class="type">  with type bandit = banditPolicy</code></div></pre><div class="info">
The Exp3 Bandit for adversarial regret minimization with a decaying learning rate as per <code class="code">[1]</code>.
</div>
<br>
<h3 id="mdf">MakeHorizonExp3: EXP3 with a known horizon <code class="code">[1]</code>.</h3>
<p>

  This variant optimizes for a known horizon $ n$ and uses the learning rate:
<p>

  $$
  \eta = \sqrt{\frac{2 ln K}{nK}}
  $$
<p>

  It has the pseudo-regret bound:
<p>

  $$
  \bar{R_n} \leq \sqrt{2 nK \ln K}
  $$<br>

<pre><span class="keyword">module type</span> <a href="Obandit.HorizonExp3Param.html">HorizonExp3Param</a> = <code class="code"><span class="keyword">sig</span></code> <a href="Obandit.HorizonExp3Param.html">..</a> <code class="code"><span class="keyword">end</span></code></pre><div class="info">
Use to instanciate a <code class="code"><span class="constructor">Bandit</span></code> from <code class="code"><span class="constructor">MakeHorizonExp3</span></code> .
</div>

<pre><span class="keyword">module</span> <a href="Obandit.MakeHorizonExp3.html">MakeHorizonExp3</a>: <div class="sig_block"><code class="code"><span class="keyword">functor</span>&nbsp;(</code><code class="code"><span class="constructor">P</span></code><code class="code">&nbsp;:&nbsp;</code><code class="type"><a href="Obandit.HorizonExp3Param.html">HorizonExp3Param</a></code><code class="code">)&nbsp;<span class="keywordsign">-&gt;</span>&nbsp;</code><code class="type"><a href="Obandit.Bandit.html">Bandit</a></code><code class="type">  with type bandit = banditPolicy</code></div></pre><div class="info">
The Exp3 Bandit for adversarial regret minimization with a horizon-based learning rate as per <code class="code">[1]</code>.
</div>
<br>
<h2 id="mdf">More Functors: The doubling trick.</h2>
<p>

  Reward normalization in online stochastic and/or adversarial learning is a hard problem.
  While this is well studied in online learning <code class="code">[2]</code><code class="code">[3]</code><code class="code">[4]</code>, there is no
  well studied procedure for bandits yet.
  The <code class="code"><span class="constructor">WrapRange</span></code> Functors applies the heuristic solution known as the doubling trick.
<p>

  The WrapRange functor wraps a bandit algorithm with the doubling trick.
  This heuristic allows to use a bandit algorithm without knowing the reward ranges. 
  All rewards are linearly rescaled to a range (initially given by a RangeParam). 
  When a value is observed above the range, the bandit algorithm is restarted and the 
  range interval is doubled in that direction.
<p>

  A convenience <code class="code"><span class="constructor">WrapRange01</span></code> is provided for rewards that are initially thought
  to lie in $\left[0,1\right]$.<br>

<pre><span class="keyword">module type</span> <a href="Obandit.RangeParam.html">RangeParam</a> = <code class="code"><span class="keyword">sig</span></code> <a href="Obandit.RangeParam.html">..</a> <code class="code"><span class="keyword">end</span></code></pre><div class="info">
A Reward range.
</div>

<pre><code><span id="TYPErangedAction"><span class="keyword">type</span> <code class="type"></code>rangedAction</span> = </code></pre><table class="typetable">
<tr>
<td align="left" valign="top" >
<code><span class="keyword">|</span></code></td>
<td align="left" valign="top" >
<code><span id="TYPEELTrangedAction.Reset"><span class="constructor">Reset</span></span> <span class="keyword">of</span> <code class="type">int</code></code></td>

</tr>
<tr>
<td align="left" valign="top" >
<code><span class="keyword">|</span></code></td>
<td align="left" valign="top" >
<code><span id="TYPEELTrangedAction.Action"><span class="constructor">Action</span></span> <span class="keyword">of</span> <code class="type">int</code></code></td>

</tr></table>

<div class="info ">
A ranged action: Action a in normal course of action, Reset a in case
* the bandit was just restarted.<br>
</div>


<pre><code><span id="TYPErangedBandit"><span class="keyword">type</span> <code class="type">'b</code> rangedBandit</span> = {</code></pre><table class="typetable">
<tr>
<td align="left" valign="top" >
<code>&nbsp;&nbsp;</code></td>
<td align="left" valign="top" >
<code><span id="TYPEELTrangedBandit.bandit">bandit</span>&nbsp;: <code class="type">'b</code>;</code></td>
<td class="typefieldcomment" align="left" valign="top" ><code>(*</code></td><td class="typefieldcomment" align="left" valign="top" ><div class="info ">
The original type of the bandit.<br>
</div>
</td><td class="typefieldcomment" align="left" valign="bottom" ><code>*)</code></td>
</tr>
<tr>
<td align="left" valign="top" >
<code>&nbsp;&nbsp;</code></td>
<td align="left" valign="top" >
<code><span id="TYPEELTrangedBandit.u">u</span>&nbsp;: <code class="type">float</code>;</code></td>
<td class="typefieldcomment" align="left" valign="top" ><code>(*</code></td><td class="typefieldcomment" align="left" valign="top" ><div class="info ">
The upper reward bound.<br>
</div>
</td><td class="typefieldcomment" align="left" valign="bottom" ><code>*)</code></td>
</tr>
<tr>
<td align="left" valign="top" >
<code>&nbsp;&nbsp;</code></td>
<td align="left" valign="top" >
<code><span id="TYPEELTrangedBandit.l">l</span>&nbsp;: <code class="type">float</code>;</code></td>
<td class="typefieldcomment" align="left" valign="top" ><code>(*</code></td><td class="typefieldcomment" align="left" valign="top" ><div class="info ">
The lower reward bound.<br>
</div>
</td><td class="typefieldcomment" align="left" valign="bottom" ><code>*)</code></td>
</tr></table>
}

<div class="info ">
The type of a bandit with a range.<br>
</div>


<pre><span class="keyword">module type</span> <a href="Obandit.RangedBandit.html">RangedBandit</a> = <code class="code"><span class="keyword">sig</span></code> <a href="Obandit.RangedBandit.html">..</a> <code class="code"><span class="keyword">end</span></code></pre><div class="info">
The type of a bandit with reward scaling.
</div>

<pre><span class="keyword">module</span> <a href="Obandit.WrapRange.html">WrapRange</a>: <div class="sig_block"><code class="code"><span class="keyword">functor</span>&nbsp;(</code><code class="code"><span class="constructor">R</span></code><code class="code">&nbsp;:&nbsp;</code><code class="type"><a href="Obandit.RangeParam.html">RangeParam</a></code><code class="code">)&nbsp;<span class="keywordsign">-&gt;</span>&nbsp;</code><div class="sig_block"><code class="code"><span class="keyword">functor</span>&nbsp;(</code><code class="code"><span class="constructor">B</span></code><code class="code">&nbsp;:&nbsp;</code><code class="type"><a href="Obandit.Bandit.html">Bandit</a></code><code class="code">)&nbsp;<span class="keywordsign">-&gt;</span>&nbsp;</code><code class="type"><a href="Obandit.RangedBandit.html">RangedBandit</a></code><code class="type">  with type bandit = B.bandit</code></div></div></pre><div class="info">
The WrapRange functor wraps a bandit algorithm with the doubling trick.
</div>

<pre><span class="keyword">module</span> <a href="Obandit.WrapRange01.html">WrapRange01</a>: <div class="sig_block"><code class="code"><span class="keyword">functor</span>&nbsp;(</code><code class="code"><span class="constructor">B</span></code><code class="code">&nbsp;:&nbsp;</code><code class="type"><a href="Obandit.Bandit.html">Bandit</a></code><code class="code">)&nbsp;<span class="keywordsign">-&gt;</span>&nbsp;</code><code class="type"><a href="Obandit.RangedBandit.html">RangedBandit</a></code><code class="type">  with type bandit = B.bandit</code></div></pre><div class="info">
The WrapRange01 functor is a convenience aliasing of WrapRange with an
  initial "standard" range of $ \left[ 0,1 \right] $.
</div>
<br>
<h1 id="ex">Examples</h1>
<p>

  see test/test.ml for an example of bandit use.
<p>

  <h1 id="refs">References</h1>
<p>

  <code class="code">[1]</code> <a href="http://arxiv.org/abs/1204.5721">Regret Analysis of Stochastic and
  Nonstochastic Multi-armed Bandit Problems</a>,
  Sebastien Bubeck and Nicolo Cesa-Bianchi.
<p>

  <code class="code">[2]</code> <a href="http://jmlr.org/papers/volume12/duchi11a/duchi11a.pdf">Adaptive Subgradient
  methods for Online Learning and Stochastic Optimization</a>,
  John Duchi , Elad Hazan and Yoram Singer.
<p>

  <code class="code">[3]</code> <a href="http://arxiv.org/abs/1305.6646">Normalized Online Learning</a>,
  Stephane Ross, Paul Mineiro, John Langford
<p>

  <code class="code">[4]</code> <a href="http://arxiv.org/abs/1601.01974">Scale-Free Online Learning</a>,
  Francesco Orabona, Dávid Pál
<p>

  <code class="code">[5]</code> <a href="http://homes.di.unimi.it/~cesabian/Pubblicazioni/ml-02.pdf">Finite-time
  Analysis of the Multiarmed Bandit Problem</a>,
  Peter Auer, Nicolo Cesa-Bianchi, Paul Fischer<br>
</body></html>