<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<link rel="stylesheet" href="style.css" type="text/css">
<meta content="text/html; charset=iso-8859-1" http-equiv="Content-Type">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="Start" href="index.html">
<link rel="Up" href="index.html">
<link title="Index of types" rel=Appendix href="index_types.html">
<link title="Index of values" rel=Appendix href="index_values.html">
<link title="Index of modules" rel=Appendix href="index_modules.html">
<link title="Index of module types" rel=Appendix href="index_module_types.html">
<link title="Obandit" rel="Chapter" href="Obandit.html"><link title="Examples" rel="Section" href="#ex">
<link title="References" rel="Section" href="#refs">
<link title="The UCB family of algorithms." rel="Subsection" href="#mdf">
<link title="The Epsilon-Greedy family of algorithms." rel="Subsection" href="#mdf">
<link title="The Exp3 family of algorithms." rel="Subsection" href="#mdf">
<link title="More Functors: The doubling trick." rel="Subsection" href="#mdf">
<title>Obandit</title>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax:{inlineMath: [ ['$','$'], ['\\(','\\)'] ],displayMath: [ ['$$','$$'], ['\\[','\\]'] ]},TeX:{Macros: {argmax: '\\mathop{\\rm arg\\,max}\\limits',}}});
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
<div class="navbar">&nbsp;<a class="up" href="index.html" title="Index">Up</a>
&nbsp;</div>
<h1>Module <a href="type_Obandit.html">Obandit</a></h1>

<pre><span id="MODULEObandit"><span class="keyword">module</span> Obandit</span>: <code class="code">sig</code> <a href="Obandit.html">..</a> <code class="code">end</code></pre><div class="info module top">
<div class="info-desc">
<p>Ocaml Multi-Armed Bandits</p>

<p>Obandit is an Ocaml module for multi-armed bandits. It supports the
EXP, UCB and Epsilon-greedy family of algorithms.</p>

<p><em>Version 0.3.4 - <a href="http://freux.fr/oss/obandit.html ">homepage</a></em></p>

<p><img src="http://freux.fr/kroliki.jpg" alt="rabbits" width="600"></p>

<h2 id="mutband">Bandit Modules</h2>
<p>This library implements multi-armed bandits as modules.
  A bandit module is obtained by calling a functor with a bandit module
  parameter. The parameter usually gives the number $K$ of arms and
  the hyperparameters of the bandit.</p>
</div>
</div>
<hr width="100%">

<pre><span id="MODULETYPEBandit"><span class="keyword">module type</span> <a href="Obandit.Bandit.html">Bandit</a></span> = <code class="code">sig</code> <a href="Obandit.Bandit.html">..</a> <code class="code">end</code></pre><div class="info">
<p>A bandit algorithm.</p>

</div>
<p>$$
  $$</p>

<p>Bandit modules are instanciated using functors. Depending on the
  algorithm type used, the module parameter varies.</p>

<p>For instance, the UCB1 bandit module for 3 arms is obtained with:</p>

<p><code class="code">module UCB1 =
  let module P = struct
  let k=3
  end
  in MakeUCB1(P)</code></p>

<p>The following algorithms are available:</p>
<h3 id="mdf">The UCB family of algorithms.</h3>
<p>We use the viewpoint of the survey <code class="code">[1]</code>.</p>

<h4 id="apu">MakeAlphaPhiUCB: $(\alpha,\psi)$-UCB </h4>
<p>At time $t$, the $(\alpha,\psi)$-UCB algorithm<code class="code">[1]</code> is taking action:</p>

<p>$$
  \argmax_{i=1,\cdots,K} \quad \left[
  \widehat{\mu_i}+(\psi^{*})^{-1}\left(\frac{\alpha\ln t}{T_i} \right) 
  \right]
  $$</p>

<p>where $\alpha &gt; 0$ is a hyperparameter, $\widehat{\mu_i}$ is the estimate of
  the average reward of arm $i$, $T_i$ is the number of times arm $ i$ was
  visited so far and $\psi^*$ denotes the Legendre-Fenchel transform of a
  convex function $\psi$.</p>

<p>The pseudo-regret $\bar{R_n}$ has the following bound at round $n$:
  $$ 
  \bar{R_n} \leq \sum_{i:\Delta_i &gt; 0} \left( \frac{\alpha \Delta_i}{\psi^* (\Delta_i / 2 )} \ln n + \frac{\alpha }{\alpha-2 } \right)
  $$</p>

<p>where $ \Delta_i = \mu^* - \mu_i $ is the suboptimality parameter of arm $ i$.</p>

<pre><code><span id="TYPEbanditEstimates"><span class="keyword">type</span> <code class="type"></code>banditEstimates</span> = {</code></pre><table class="typetable">
<tr>
<td align="left" valign="top" >
<code>&nbsp;&nbsp;</code></td>
<td align="left" valign="top" >
<code><span id="TYPEELTbanditEstimates.t">t</span>&nbsp;: <code class="type">int</code>;</code></td>
<td class="typefieldcomment" align="left" valign="top" ><code>(*</code></td><td class="typefieldcomment" align="left" valign="top" ><div class="info ">
<div class="info-desc">
<p>The index of the step</p>
</div>
</div>
</td><td class="typefieldcomment" align="left" valign="bottom" ><code>*)</code></td>
</tr>
<tr>
<td align="left" valign="top" >
<code>&nbsp;&nbsp;</code></td>
<td align="left" valign="top" >
<code><span id="TYPEELTbanditEstimates.a">a</span>&nbsp;: <code class="type">int</code>;</code></td>
<td class="typefieldcomment" align="left" valign="top" ><code>(*</code></td><td class="typefieldcomment" align="left" valign="top" ><div class="info ">
<div class="info-desc">
<p>The last action taken.</p>
</div>
</div>
</td><td class="typefieldcomment" align="left" valign="bottom" ><code>*)</code></td>
</tr>
<tr>
<td align="left" valign="top" >
<code>&nbsp;&nbsp;</code></td>
<td align="left" valign="top" >
<code><span id="TYPEELTbanditEstimates.nVisits">nVisits</span>&nbsp;: <code class="type">int list</code>;</code></td>
<td class="typefieldcomment" align="left" valign="top" ><code>(*</code></td><td class="typefieldcomment" align="left" valign="top" ><div class="info ">
<div class="info-desc">
<p>The visit counts by arm.</p>
</div>
</div>
</td><td class="typefieldcomment" align="left" valign="bottom" ><code>*)</code></td>
</tr>
<tr>
<td align="left" valign="top" >
<code>&nbsp;&nbsp;</code></td>
<td align="left" valign="top" >
<code><span id="TYPEELTbanditEstimates.u">u</span>&nbsp;: <code class="type">float list</code>;</code></td>
<td class="typefieldcomment" align="left" valign="top" ><code>(*</code></td><td class="typefieldcomment" align="left" valign="top" ><div class="info ">
<div class="info-desc">
<p>The cumulative arm reward observations.</p>
</div>
</div>
</td><td class="typefieldcomment" align="left" valign="bottom" ><code>*)</code></td>
</tr></table>
}

<div class="info ">
<div class="info-desc">
<p>The inner state of a bandit that maintains estimates of arm means.</p>
</div>
</div>


<pre><span id="MODULETYPEAlphaPhiUCBParam"><span class="keyword">module type</span> <a href="Obandit.AlphaPhiUCBParam.html">AlphaPhiUCBParam</a></span> = <code class="code">sig</code> <a href="Obandit.AlphaPhiUCBParam.html">..</a> <code class="code">end</code></pre><div class="info">
<p>Use to instanciate a <code class="code">Bandit</code> from <code class="code">MakeAlphaPhiUCB</code> by giving $\alpha$ and $\phi$.</p>

</div>

<pre><span id="MODULEMakeAlphaPhiUCB"><span class="keyword">module</span> <a href="Obandit.MakeAlphaPhiUCB.html">MakeAlphaPhiUCB</a></span>: <div class="sig_block"><code class="code">functor (</code><code class="code">P</code><code class="code"> : </code><code class="type"><a href="Obandit.AlphaPhiUCBParam.html">AlphaPhiUCBParam</a></code><code class="code">) -&gt; </code><code class="type"><a href="Obandit.Bandit.html">Bandit</a></code><code class="type">  with type bandit = banditEstimates</code></div></pre><div class="info">
<p>The $(\alpha,\psi)$-UCB Bandit for stochastic regret minimization described in <code class="code">[1]</code>.</p>

</div>
<h4 id="apu">MakeAlphaUCB: $\alpha$-UCB </h4>
<p>The $\alpha$-UCB algorithm<code class="code">[5]</code> uses $ \psi(\lambda) = \lambda^2 / 8 $.
  It chooses the action:</p>

<p>$$ 
  \argmax_{i=1,\cdots,K} \left[ \widehat{\mu_i} +  \sqrt{ \frac{\alpha \ln t}{2 T_i} } \right]
  $$</p>

<p>This gives a pseudo-regret bound of:</p>

<p>$$ 
  \bar{ R_n} \leq  \sum_{i:\Delta_i &gt; 0} \left( \frac{2 \alpha} { \Delta_i } \ln n + \frac{\alpha}{\alpha - 2} \right)
  $$</p>

<pre><span id="MODULETYPEAlphaUCBParam"><span class="keyword">module type</span> <a href="Obandit.AlphaUCBParam.html">AlphaUCBParam</a></span> = <code class="code">sig</code> <a href="Obandit.AlphaUCBParam.html">..</a> <code class="code">end</code></pre><div class="info">
<p>Use to instanciate a <code class="code">Bandit</code> from <code class="code">MakeAlphaUCB</code> by giving $\alpha$.</p>

</div>

<pre><span id="MODULEMakeAlphaUCB"><span class="keyword">module</span> <a href="Obandit.MakeAlphaUCB.html">MakeAlphaUCB</a></span>: <div class="sig_block"><code class="code">functor (</code><code class="code">P</code><code class="code"> : </code><code class="type"><a href="Obandit.AlphaUCBParam.html">AlphaUCBParam</a></code><code class="code">) -&gt; </code><code class="type"><a href="Obandit.Bandit.html">Bandit</a></code><code class="type">  with type bandit = banditEstimates</code></div></pre><div class="info">
<p>The $\alpha$-UCB Bandit for stochastic regret minimization described in <code class="code">[1]</code> .</p>

</div>
<h4 id="apu">MakeUCB1: UCB1</h4>
<p>The UCB1 algorithm<code class="code">[5]</code> uses $\alpha = 4$.
  It chooses the action:</p>

<p>$$
  \argmax_{i=1,\cdots,K} \left[ \widehat{\mu_i} +  \sqrt{ \frac{2 \ln t}{T_i} } \right]
  $$</p>

<p>At round  $ n$, this gives a pseudo-regret bound of:</p>

<p>$$
  \bar{R_n} \leq \sum_{i:\Delta_i &gt; 0} \left( \frac{8}{\Delta_i} \ln n + 2 \right)
  $$</p>

<pre><span id="MODULETYPEKBanditParam"><span class="keyword">module type</span> <a href="Obandit.KBanditParam.html">KBanditParam</a></span> = <code class="code">sig</code> <a href="Obandit.KBanditParam.html">..</a> <code class="code">end</code></pre><div class="info">
<p>Use to instanciate a <code class="code">Bandit</code> from <code class="code">MakeUCB1</code>.</p>

</div>

<pre><span id="MODULEMakeUCB1"><span class="keyword">module</span> <a href="Obandit.MakeUCB1.html">MakeUCB1</a></span>: <div class="sig_block"><code class="code">functor (</code><code class="code">P</code><code class="code"> : </code><code class="type"><a href="Obandit.KBanditParam.html">KBanditParam</a></code><code class="code">) -&gt; </code><code class="type"><a href="Obandit.Bandit.html">Bandit</a></code><code class="type">  with type bandit = banditEstimates</code></div></pre><div class="info">
<p>The UCB1 Bandit for stochastic regret minimization .</p>

</div>
<h3 id="mdf">The Epsilon-Greedy family of algorithms.</h3>
<h4 id="mdf">MakeParametrizableEpsilonGreedy: $\epsilon$-Greedy with a parametrizable rate.</h4>
<p>At round $t$, the $ \epsilon_t$-Greedy algorithm<code class="code">[5]</code> takes action $\argmax_{i=1,\cdots,K} \widehat{\mu_i} $
  with probability $ 1-\epsilon_t$ and an uniformly random action with probability $ \epsilon_t$.</p>

<pre><span id="MODULETYPERateBanditParam"><span class="keyword">module type</span> <a href="Obandit.RateBanditParam.html">RateBanditParam</a></span> = <code class="code">sig</code> <a href="Obandit.RateBanditParam.html">..</a> <code class="code">end</code></pre><div class="info">
<p>Use to instanciate algorithms that need a parametrizable rate.</p>

</div>

<pre><span id="MODULEMakeParametrizableEpsilonGreedy"><span class="keyword">module</span> <a href="Obandit.MakeParametrizableEpsilonGreedy.html">MakeParametrizableEpsilonGreedy</a></span>: <div class="sig_block"><code class="code">functor (</code><code class="code">P</code><code class="code"> : </code><code class="type"><a href="Obandit.RateBanditParam.html">RateBanditParam</a></code><code class="code">) -&gt; </code><code class="type"><a href="Obandit.Bandit.html">Bandit</a></code><code class="type">  with type bandit = banditEstimates</code></div></pre><div class="info">
<p>The $\epsilon$-Greedy Bandit with a parametrizable exploration rate.</p>

</div>
<h4 id="mdf">MakeDecayingEpsilonGreedy: $ \epsilon_n$-Greedy with the decaying rate from <code class="code">[5]</code>.</h4>
<p>This uses the exploration rate decay:
  $$
  \epsilon_t = \min  \left\{ 1, \frac{cK}{d^2 t} \right\}
  $$
  where $ d &gt; 0 $ should be taken as a tight lower bound on $ \max_{i=1,\cdots,K} \Delta_i$ and $ c &gt; 0$ is a hyperparameter.</p>

<pre><span id="MODULETYPEDecayingEpsilonGreedyParam"><span class="keyword">module type</span> <a href="Obandit.DecayingEpsilonGreedyParam.html">DecayingEpsilonGreedyParam</a></span> = <code class="code">sig</code> <a href="Obandit.DecayingEpsilonGreedyParam.html">..</a> <code class="code">end</code></pre><div class="info">
<p>Use to instanciate a <code class="code">Bandit</code> from <code class="code">MakeDecayingEpsilonGreedy</code> .</p>

</div>

<pre><span id="MODULEMakeDecayingEpsilonGreedy"><span class="keyword">module</span> <a href="Obandit.MakeDecayingEpsilonGreedy.html">MakeDecayingEpsilonGreedy</a></span>: <div class="sig_block"><code class="code">functor (</code><code class="code">P</code><code class="code"> : </code><code class="type"><a href="Obandit.DecayingEpsilonGreedyParam.html">DecayingEpsilonGreedyParam</a></code><code class="code">) -&gt; </code><code class="type"><a href="Obandit.Bandit.html">Bandit</a></code><code class="type">  with type bandit = banditEstimates</code></div></pre><div class="info">
<p>The Epsilon-Greedy Bandit with the decaying exploration rate from <code class="code">[5]</code>.</p>

</div>
<h4 id="mdf">MakeEpsilonGreedy: $ \epsilon_n$-Greedy with a fixed exploration rate.</h4>
<p>This uses a fixed exploration rate $ \epsilon$.</p>

<pre><span id="MODULETYPEEpsilonGreedyParam"><span class="keyword">module type</span> <a href="Obandit.EpsilonGreedyParam.html">EpsilonGreedyParam</a></span> = <code class="code">sig</code> <a href="Obandit.EpsilonGreedyParam.html">..</a> <code class="code">end</code></pre><div class="info">
<p>Use to instanciate a <code class="code">Bandit</code> from <code class="code">MakeEpsilonGreedy</code> .</p>

</div>

<pre><span id="MODULEMakeEpsilonGreedy"><span class="keyword">module</span> <a href="Obandit.MakeEpsilonGreedy.html">MakeEpsilonGreedy</a></span>: <div class="sig_block"><code class="code">functor (</code><code class="code">P</code><code class="code"> : </code><code class="type"><a href="Obandit.EpsilonGreedyParam.html">EpsilonGreedyParam</a></code><code class="code">) -&gt; </code><code class="type"><a href="Obandit.Bandit.html">Bandit</a></code><code class="type">  with type bandit = banditEstimates</code></div></pre><div class="info">
<p>The Epsilon-Greedy Bandit with a fixed exploration rate.</p>

</div>
<h3 id="mdf">The Exp3 family of algorithms.</h3>
<h4 id="mdf">MakeExp3: EXP3 with a parametrizable rate.</h4>
<p>At round $ t$, the EXP3 algorithm<code class="code">[1]</code> draws an arm from a probability
  distribution $ p$ and updates this distribution with a softmax operator:</p>

<p>$
  p_{i,t+1} = \frac{\exp ( - \eta_t \widetilde{L_{i,t}})}{\sum{k=1}^{K}\text{exp}(-\eta_t \widetilde{L_{k,t}})}
  $</p>

<p>where $\widetilde{L_{i,t}}$ is the cumulative probability-normalized loss at
  time $ t$ of arm $i$, $\eta_t$ is the rate at time $t$.</p>

<pre><code><span id="TYPEbanditPolicy"><span class="keyword">type</span> <code class="type"></code>banditPolicy</span> = {</code></pre><table class="typetable">
<tr>
<td align="left" valign="top" >
<code>&nbsp;&nbsp;</code></td>
<td align="left" valign="top" >
<code><span id="TYPEELTbanditPolicy.t">t</span>&nbsp;: <code class="type">int</code>;</code></td>
<td class="typefieldcomment" align="left" valign="top" ><code>(*</code></td><td class="typefieldcomment" align="left" valign="top" ><div class="info ">
<div class="info-desc">
<p>The index of the step $t$.</p>
</div>
</div>
</td><td class="typefieldcomment" align="left" valign="bottom" ><code>*)</code></td>
</tr>
<tr>
<td align="left" valign="top" >
<code>&nbsp;&nbsp;</code></td>
<td align="left" valign="top" >
<code><span id="TYPEELTbanditPolicy.a">a</span>&nbsp;: <code class="type">int</code>;</code></td>
<td class="typefieldcomment" align="left" valign="top" ><code>(*</code></td><td class="typefieldcomment" align="left" valign="top" ><div class="info ">
<div class="info-desc">
<p>The last action taken.</p>
</div>
</div>
</td><td class="typefieldcomment" align="left" valign="bottom" ><code>*)</code></td>
</tr>
<tr>
<td align="left" valign="top" >
<code>&nbsp;&nbsp;</code></td>
<td align="left" valign="top" >
<code><span id="TYPEELTbanditPolicy.w">w</span>&nbsp;: <code class="type">float list</code>;</code></td>
<td class="typefieldcomment" align="left" valign="top" ><code>(*</code></td><td class="typefieldcomment" align="left" valign="top" ><div class="info ">
<div class="info-desc">
<p>The weights of the arm that define the policy.</p>
</div>
</div>
</td><td class="typefieldcomment" align="left" valign="bottom" ><code>*)</code></td>
</tr></table>
}

<div class="info ">
<div class="info-desc">
<p>The internal state of an Exp3 bandit</p>
</div>
</div>


<pre><span id="MODULEMakeExp3"><span class="keyword">module</span> <a href="Obandit.MakeExp3.html">MakeExp3</a></span>: <div class="sig_block"><code class="code">functor (</code><code class="code">P</code><code class="code"> : </code><code class="type"><a href="Obandit.RateBanditParam.html">RateBanditParam</a></code><code class="code">) -&gt; </code><code class="type"><a href="Obandit.Bandit.html">Bandit</a></code><code class="type">  with type bandit = banditPolicy</code></div></pre><div class="info">
<p>The Exp3 Bandit for adversarial regret minimization with a parametrizable learning rate.</p>

</div>
<h4 id="mdf">MakeDecayingExp3: EXP3 with the decaying rate from <code class="code">[1]</code>.</h4>
<p>This variant uses the learning rate decay:</p>

<p>$$
  \eta_t = \sqrt{\frac{ln K}{tK}}
  $$</p>

<p>and enjoys the pseudo-regret bound:
  $$
  \bar{R_n} \leq 2 \sqrt{nK \ln K}
  $$</p>

<pre><span id="MODULEMakeDecayingExp3"><span class="keyword">module</span> <a href="Obandit.MakeDecayingExp3.html">MakeDecayingExp3</a></span>: <div class="sig_block"><code class="code">functor (</code><code class="code">P</code><code class="code"> : </code><code class="type"><a href="Obandit.KBanditParam.html">KBanditParam</a></code><code class="code">) -&gt; </code><code class="type"><a href="Obandit.Bandit.html">Bandit</a></code><code class="type">  with type bandit = banditPolicy</code></div></pre><div class="info">
<p>The Exp3 Bandit for adversarial regret minimization with a decaying learning rate as per <code class="code">[1]</code>.</p>

</div>
<h4 id="mdf">MakeFixedExp3: EXP3 with a fixed rate.</h4>
<p>This uses a fixed rate $\eta$.</p>

<pre><span id="MODULETYPEFixedExp3Param"><span class="keyword">module type</span> <a href="Obandit.FixedExp3Param.html">FixedExp3Param</a></span> = <code class="code">sig</code> <a href="Obandit.FixedExp3Param.html">..</a> <code class="code">end</code></pre><div class="info">
<p>Use to instanciate a <code class="code">Bandit</code> from <code class="code">MakeFixedExp3</code> .</p>

</div>

<pre><span id="MODULEMakeFixedExp3"><span class="keyword">module</span> <a href="Obandit.MakeFixedExp3.html">MakeFixedExp3</a></span>: <div class="sig_block"><code class="code">functor (</code><code class="code">P</code><code class="code"> : </code><code class="type"><a href="Obandit.FixedExp3Param.html">FixedExp3Param</a></code><code class="code">) -&gt; </code><code class="type"><a href="Obandit.Bandit.html">Bandit</a></code><code class="type">  with type bandit = banditPolicy</code></div></pre><div class="info">
<p>The Exp3 Bandit for adversarial regret minimization with a decaying learning rate as per <code class="code">[1]</code>.</p>

</div>
<h4 id="mdf">MakeHorizonExp3: EXP3 with a known horizon <code class="code">[1]</code>.</h4>
<p>This variant optimizes for a known horizon $ n$ and uses the learning rate:</p>

<p>$$
  \eta = \sqrt{\frac{2 ln K}{nK}}
  $$</p>

<p>It has the pseudo-regret bound:</p>

<p>$$
  \bar{R_n} \leq \sqrt{2 nK \ln K}
  $$</p>

<pre><span id="MODULETYPEHorizonExp3Param"><span class="keyword">module type</span> <a href="Obandit.HorizonExp3Param.html">HorizonExp3Param</a></span> = <code class="code">sig</code> <a href="Obandit.HorizonExp3Param.html">..</a> <code class="code">end</code></pre><div class="info">
<p>Use to instanciate a <code class="code">Bandit</code> from <code class="code">MakeHorizonExp3</code> .</p>

</div>

<pre><span id="MODULEMakeHorizonExp3"><span class="keyword">module</span> <a href="Obandit.MakeHorizonExp3.html">MakeHorizonExp3</a></span>: <div class="sig_block"><code class="code">functor (</code><code class="code">P</code><code class="code"> : </code><code class="type"><a href="Obandit.HorizonExp3Param.html">HorizonExp3Param</a></code><code class="code">) -&gt; </code><code class="type"><a href="Obandit.Bandit.html">Bandit</a></code><code class="type">  with type bandit = banditPolicy</code></div></pre><div class="info">
<p>The Exp3 Bandit for adversarial regret minimization with a horizon-based learning rate as per <code class="code">[1]</code>.</p>

</div>
<h3 id="mdf">More Functors: The doubling trick.</h3>
<p>Reward normalization in online stochastic and/or adversarial learning is a hard problem.
  While this is well studied in online learning <code class="code">[2]</code><code class="code">[3]</code><code class="code">[4]</code>, there is no
  well studied procedure for bandits yet.
  The <code class="code">WrapRange</code> Functors applies the heuristic solution known as the doubling trick.</p>

<p>The WrapRange functor wraps a bandit algorithm with the doubling trick.
  This heuristic allows to use a bandit algorithm without knowing the reward ranges. 
  All rewards are linearly rescaled to a range (initially given by a RangeParam). 
  When a value is observed above the range, the bandit algorithm is restarted and the 
  range interval is doubled in that direction.</p>

<p>A convenience <code class="code">WrapRange01</code> is provided for rewards that are initially thought
  to lie in $\left[0,1\right]$.</p>

<pre><span id="MODULETYPERangeParam"><span class="keyword">module type</span> <a href="Obandit.RangeParam.html">RangeParam</a></span> = <code class="code">sig</code> <a href="Obandit.RangeParam.html">..</a> <code class="code">end</code></pre><div class="info">
<p>A Reward range.</p>

</div>

<pre><code><span id="TYPErangedAction"><span class="keyword">type</span> <code class="type"></code>rangedAction</span> = </code></pre><table class="typetable">
<tr>
<td align="left" valign="top" >
<code><span class="keyword">|</span></code></td>
<td align="left" valign="top" >
<code><span id="TYPEELTrangedAction.Reset"><span class="constructor">Reset</span></span> <span class="keyword">of</span> <code class="type">int</code></code></td>

</tr>
<tr>
<td align="left" valign="top" >
<code><span class="keyword">|</span></code></td>
<td align="left" valign="top" >
<code><span id="TYPEELTrangedAction.Action"><span class="constructor">Action</span></span> <span class="keyword">of</span> <code class="type">int</code></code></td>

</tr></table>

<div class="info ">
<div class="info-desc">
<p>A ranged action: Action a in normal course of action, Reset a in case
* the bandit was just restarted.</p>
</div>
</div>


<pre><code><span id="TYPErangedBandit"><span class="keyword">type</span> <code class="type">'b</code> rangedBandit</span> = {</code></pre><table class="typetable">
<tr>
<td align="left" valign="top" >
<code>&nbsp;&nbsp;</code></td>
<td align="left" valign="top" >
<code><span id="TYPEELTrangedBandit.bandit">bandit</span>&nbsp;: <code class="type">'b</code>;</code></td>
<td class="typefieldcomment" align="left" valign="top" ><code>(*</code></td><td class="typefieldcomment" align="left" valign="top" ><div class="info ">
<div class="info-desc">
<p>The original type of the bandit.</p>
</div>
</div>
</td><td class="typefieldcomment" align="left" valign="bottom" ><code>*)</code></td>
</tr>
<tr>
<td align="left" valign="top" >
<code>&nbsp;&nbsp;</code></td>
<td align="left" valign="top" >
<code><span id="TYPEELTrangedBandit.u">u</span>&nbsp;: <code class="type">float</code>;</code></td>
<td class="typefieldcomment" align="left" valign="top" ><code>(*</code></td><td class="typefieldcomment" align="left" valign="top" ><div class="info ">
<div class="info-desc">
<p>The upper reward bound.</p>
</div>
</div>
</td><td class="typefieldcomment" align="left" valign="bottom" ><code>*)</code></td>
</tr>
<tr>
<td align="left" valign="top" >
<code>&nbsp;&nbsp;</code></td>
<td align="left" valign="top" >
<code><span id="TYPEELTrangedBandit.l">l</span>&nbsp;: <code class="type">float</code>;</code></td>
<td class="typefieldcomment" align="left" valign="top" ><code>(*</code></td><td class="typefieldcomment" align="left" valign="top" ><div class="info ">
<div class="info-desc">
<p>The lower reward bound.</p>
</div>
</div>
</td><td class="typefieldcomment" align="left" valign="bottom" ><code>*)</code></td>
</tr></table>
}

<div class="info ">
<div class="info-desc">
<p>The type of a bandit with a range.</p>
</div>
</div>


<pre><span id="MODULETYPERangedBandit"><span class="keyword">module type</span> <a href="Obandit.RangedBandit.html">RangedBandit</a></span> = <code class="code">sig</code> <a href="Obandit.RangedBandit.html">..</a> <code class="code">end</code></pre><div class="info">
<p>The type of a bandit with reward scaling.</p>

</div>

<pre><span id="MODULEWrapRange"><span class="keyword">module</span> <a href="Obandit.WrapRange.html">WrapRange</a></span>: <div class="sig_block"><code class="code">functor (</code><code class="code">R</code><code class="code"> : </code><code class="type"><a href="Obandit.RangeParam.html">RangeParam</a></code><code class="code">) -&gt; </code><div class="sig_block"><code class="code">functor (</code><code class="code">B</code><code class="code"> : </code><code class="type"><a href="Obandit.Bandit.html">Bandit</a></code><code class="code">) -&gt; </code><code class="type"><a href="Obandit.RangedBandit.html">RangedBandit</a></code><code class="type">  with type bandit = B.bandit</code></div></div></pre><div class="info">
<p>The WrapRange functor wraps a bandit algorithm with the doubling trick.</p>

</div>

<pre><span id="MODULEWrapRange01"><span class="keyword">module</span> <a href="Obandit.WrapRange01.html">WrapRange01</a></span>: <div class="sig_block"><code class="code">functor (</code><code class="code">B</code><code class="code"> : </code><code class="type"><a href="Obandit.Bandit.html">Bandit</a></code><code class="code">) -&gt; </code><code class="type"><a href="Obandit.RangedBandit.html">RangedBandit</a></code><code class="type">  with type bandit = B.bandit</code></div></pre><div class="info">
<p>The WrapRange01 functor is a convenience aliasing of WrapRange with an
  initial "standard" range of $ \left[ 0,1 \right] $.</p>

</div>
<h2 id="ex">Examples</h2>
<p>see test/test.ml for an example of bandit use.</p>

<h2 id="refs">References</h2>
<p><code class="code">[1]</code> <a href="http://arxiv.org/abs/1204.5721">Regret Analysis of Stochastic and
  Nonstochastic Multi-armed Bandit Problems</a>,
  Sebastien Bubeck and Nicolo Cesa-Bianchi.</p>

<p><code class="code">[2]</code> <a href="http://jmlr.org/papers/volume12/duchi11a/duchi11a.pdf">Adaptive Subgradient
  methods for Online Learning and Stochastic Optimization</a>,
  John Duchi , Elad Hazan and Yoram Singer.</p>

<p><code class="code">[3]</code> <a href="http://arxiv.org/abs/1305.6646">Normalized Online Learning</a>,
  Stephane Ross, Paul Mineiro, John Langford</p>

<p><code class="code">[4]</code> <a href="http://arxiv.org/abs/1601.01974">Scale-Free Online Learning</a>,
  Francesco Orabona, Dávid Pál</p>

<p><code class="code">[5]</code> <a href="http://homes.di.unimi.it/~cesabian/Pubblicazioni/ml-02.pdf">Finite-time
  Analysis of the Multiarmed Bandit Problem</a>,
  Peter Auer, Nicolo Cesa-Bianchi, Paul Fischer</p>
</body></html>